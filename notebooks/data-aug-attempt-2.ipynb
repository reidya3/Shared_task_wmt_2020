{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmenation attempt 2 \n",
    "### EN-DE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading in all the different augmeneted data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_lines = []\n",
    "english_lines = []\n",
    "with open(\"../data-augmented_2/en-de/orginial/rapid2019.de-en.de\", encoding=\"UTF-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\r', '').replace('\\n', '').strip()\n",
    "        if len(line) > 0:\n",
    "            german_lines.append(line)\n",
    "with open(\"../data-augmented_2/en-de/orginial/rapid2019.de-en.en\", encoding=\"UTF-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\r', '').replace('\\n', '').strip()\n",
    "        if len(line) > 0:\n",
    "            english_lines.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"orginal\":english_lines, \"translation\":german_lines}\n",
    "rapid_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europarl_df =  pd.read_csv('../data-augmented_2/en-de/orginial/europarl-v9.de-en.tsv',sep=\"\\t\", error_bad_lines=False, names = [\"translation\", \"orginal\"])\n",
    "europarl_df = europarl_df.dropna()\n",
    "europarl_df = europarl_df[[\"orginal\", \"translation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newscomm_df =  pd.read_csv('../data-augmented_2/en-de/orginial/news-commentary-v14.tsv',sep=\"\\t\", names = [\"translation\",  \"orginal\"], error_bad_lines=False)\n",
    "newscomm_df = newscomm_df.dropna()\n",
    "newscomm_df = newscomm_df[[\"orginal\", \"translation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combining all the seperate datframes into one result df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([rapid_df, europarl_df, newscomm_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.dropna()\n",
    "result_df[\"orginal\"] = result_df[\"orginal\"].apply(lambda x: x.replace('\\r', '').replace('\\n', '').strip())\n",
    "result_df[\"translation\"] = result_df[\"translation\"].apply(lambda x: x.replace('\\r', '').replace('\\n', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"../data-augmented_2/en-de/orginial/result.tsv\", index = None, header=True,sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence similairty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_de_test_df = pd.read_csv(\"../data/en-de-test/test20.ende.df.short.tsv\" ,sep=\"\\t\")\n",
    "#result_df =\n",
    "pd.read_csv(\"../data-augmented_2/en-de/orginial/result.tsv\", sep = '\\t')\n",
    "en_de_train_df =  pd.read_csv(\"../data/en-de/train.ende.df.short.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[i for i in newscomm_df[\"orginal\"].to_list() if i != ''and len(i.split(' '))>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = model.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = en_de_test_df[\"original\"].to_list()\n",
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 20\n",
    "similar_sentence_list = []\n",
    "score_list = []\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        similar_sentence_list.append(corpus[idx].strip())\n",
    "        score_list.append((1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"sentence\":similar_sentence_list ,\"score\":score_list}\n",
    "score_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2000_df = score_df.sort_values(by=['score'], ascending=False).drop_duplicates(subset=[\"sentence\"],keep=\"first\")[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2000_df.reset_index(inplace=True,drop=True)\n",
    "newscomm_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_df = pd.DataFrame()\n",
    "for index, sentence in score_2000_df[\"sentence\"].items():\n",
    "    print(index)\n",
    "    try:\n",
    "        wanted_index=None\n",
    "        wanted_index = newscomm_df[newscomm_df['orginal'] == sentence]\n",
    "        data_aug_df = pd.concat([data_aug_df,wanted_index], ignore_index=True)\n",
    "    #soemtimes the text transquest is not exactly the same as the orginial feature of the dev data        \n",
    "    except IndexError:\n",
    "        wanted_index = None\n",
    "        matched_string = process.extractOne(sentence,newscomm_df[\"orginal\"].values.tolist())[0]\n",
    "        wanted_index = newscomm_df[newscomm_df['orginal'] == matched_string]\n",
    "        print(sentence)\n",
    "        print(wanted_index)\n",
    "        data_aug_df = pd.concat([data_aug_df,wanted_index], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_df = data_aug_df.drop_duplicates(subset=[\"orginal\"],keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_df.rename(columns={'orginal': 'original'}, inplace=True)\n",
    "data_aug_df[\"scores\"]= None\n",
    "data_aug_df[\"mean\"]= None\n",
    "data_aug_df[\"z_scores\"]= None\n",
    "data_aug_df[\"z_mean\"]= 2.743416\n",
    "data_aug_df[\"model_scores\"]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_df = pd.concat([en_de_train_df, data_aug_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_df.to_csv(\"../data-augmented_2/en-de/augmented/result.tsv\",index = None, header=True,sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
